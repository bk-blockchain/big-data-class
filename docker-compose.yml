version: '3.7'
services:
  spark_master:
    container_name: spark_master
    image: spark_master:latest
    hostname: master
    build:
      context: .
      dockerfile: Dockerfile.master
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=local[*]
      - MASTER=local[*]
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=2G
      - SPARK_DRIVER_MEMORY=512m
      - SPARK_EXECUTOR_MEMORY=512m
      - SPARK_DAEMON_MEMORY=4G
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - 4040:4040
      - 7077:7077
      - 8080:8080
      - 6066:6066
      - 8081:8081
      - 80:80
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.10
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 4096M
        reservations:
          cpus: '1'
          memory: 4096M
    volumes:
      - './notebook:/usr/zeppelin/notebook'

  spark_worker_01:
    container_name: spark_worker_01
    image: spark_master:latest
    hostname: worker_01
    build:
      context: .
      dockerfile: Dockerfile.worker
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "8082:8081"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.11
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"

  spark_worker_02:
    container_name: spark_worker_02
    image: spark_master:latest
    hostname: worker_02
    build:
      context: .
      dockerfile: Dockerfile.worker
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "8083:8081"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.12
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"

  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:3-management
    hostname: rabbitmq
    build:
      context: .
      dockerfile: Dockerfile.rabbitmq
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "15672:15672"
      - "5672:5672"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.13
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.2.4
    container_name: elasticsearch
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    build:
      context: .
      dockerfile: Dockerfile.elasticsearch
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - './elasticsearch/esdata1:/usr/share/elasticsearch/data'
    ports:
      - 9200:9200
    networks:
      spark-network:
        ipv4_address: 10.0.1.14

  elasticsearch2:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.2.4
    container_name: elasticsearch2
    build:
      context: .
      dockerfile: Dockerfile.elasticsearch
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "discovery.zen.ping.unicast.hosts=elasticsearch"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - './elasticsearch/esdata2:/usr/share/elasticsearch/data'
    networks:
      spark-network:
        ipv4_address: 10.0.1.15

  kibana:
    image: 'docker.elastic.co/kibana/kibana:6.3.2'
    container_name: kibana
    environment:
      SERVER_NAME: kibana.local
      ELASTICSEARCH_URL: http://elasticsearch:9200
    ports:
      - '5601:5601'
    networks:
      spark-network:
        ipv4_address: 10.0.1.16

networks:
  spark-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.0.1.0/24
