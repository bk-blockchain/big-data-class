version: '3.7'
services:
  spark_master:
    container_name: spark_master
    image: spark_master:latest
    hostname: master
    build:
      context: .
      dockerfile: Dockerfile.master
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=2G
      - SPARK_DRIVER_MEMORY=512m
      - SPARK_EXECUTOR_MEMORY=512m
      - SPARK_DAEMON_MEMORY=4G
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - 4040:4040
      - 7077:7077
      - 8080:8080
      - 6066:6066
      - 8081:8081
      - 80:80
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.10
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 4096M
        reservations:
          cpus: '1'
          memory: 4096M

  spark_worker_01:
    container_name: spark_worker_01
    image: spark_master:latest
    hostname: worker_01
    build:
      context: .
      dockerfile: Dockerfile.worker
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "8082:8081"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.11
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"

  spark_worker_02:
    container_name: spark_worker_02
    image: spark_master:latest
    hostname: worker_02
    build:
      context: .
      dockerfile: Dockerfile.worker
      labels:
        com.bkwallet.description: "Big Data Class"
        com.bkwallet.maintainer: "ChungDT <chungdt@soict.hust.edu.vn>"
    environment:
      - ZEPPELIN_PORT=80
      - SPARK_MASTER=spark://master:7077
      - MASTER=spark://master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
    healthcheck:
      disable: true
    dns:
      - 8.8.8.8
      - 8.8.4.4
    ports:
      - "8083:8081"
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "2"
    restart: "always"
    networks:
      spark-network:
        ipv4_address: 10.0.1.12
    extra_hosts:
      - "master:10.0.1.10"
      - "worker_01:10.0.1.11"
      - "worker_02:10.0.1.12"

networks:
  spark-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 10.0.1.0/24
